{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "import h5py\n",
    "from tqdm import tqdm_notebook\n",
    "from time import time as timer\n",
    "from skimage.external.tifffile import imsave\n",
    "from IPython.display import clear_output\n",
    "from os import path as op\n",
    "from sys import path as sp\n",
    "module_path = op.abspath(op.join('..'))\n",
    "if module_path not in sp:  # add local path to import helpers\n",
    "    sp.append(module_path)\n",
    "import helpers as h\n",
    "from importlib import reload\n",
    "from IPython.display import display_html\n",
    "import deepdish as dd\n",
    "from types import SimpleNamespace as NS\n",
    "h = reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_THREADS         = 0 #h.getAvailableThreadCount()-2\n",
    "GPU_THREADS         = 8 #2\n",
    "\n",
    "FRAMES_PER_CHUNK    = 16    # more Frames will need more RAM but speed up process (max: 95)\n",
    "COMPRESSION         = None  # http://docs.h5py.org/en/latest/high/dataset.html#lossless-compression-filters\n",
    "ALIGNMENT_FRAME_IDX = 0     # Frame idx to which others will be aligned (starting at 0) \n",
    "MAX_DISPLACEMENT    = 30    # if displacement of frame is higher it will be discarded\n",
    "DELETE_LAST_H5_FILE = True  # if h5-File already exists it will be deleted\n",
    "\n",
    "FILE_NAME = \"./data/fish4_stimulus.lif\"\n",
    "TEMPLATE_FILE_NAME = \"./data/cell.tif\"\n",
    "\n",
    "H5_FILE_NAME = FILE_NAME.replace(\".lif\", \".hdf5\")\n",
    "STD_DEV_FILE_NAME = FILE_NAME.replace(\".lif\", \"_std_div.tif\")\n",
    "INVALID_FRAMES_FILE_NAME = FILE_NAME.replace(\".lif\", \"_invalid_frames.npy\")\n",
    "DATA_SET_NAME = \"ImageStack\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read stack, align images and save to hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_THREADS = 1\n",
    "# prepare reader\n",
    "ir, shape, metaData = h.startLifReader(FILE_NAME, FRAMES_PER_CHUNK)\n",
    "nf, nz, nx, ny = shape\n",
    "print(\"Found image stack of shape  {}\".format(shape))\n",
    "\n",
    "# prepare chunks\n",
    "chunkShape = (FRAMES_PER_CHUNK, nz, nx, ny)\n",
    "chunkCount = nf // FRAMES_PER_CHUNK\n",
    "chunkPair = (np.empty(chunkShape, dtype=np.uint16), np.empty(chunkShape, dtype=np.uint16))\n",
    "\n",
    "if (DELETE_LAST_H5_FILE): h.removeIfExists(H5_FILE_NAME)\n",
    "    \n",
    "# create Threads and Queues for image alignment\n",
    "frameQueuePair = (h.createQueue(h.alignFrameWorker, FRAMES_PER_CHUNK, CPU_THREADS, GPU_THREADS),\n",
    "                  h.createQueue(h.alignFrameWorker, FRAMES_PER_CHUNK, CPU_THREADS, GPU_THREADS))\n",
    "\n",
    "h.prepareAlignmentFrame(h.readFrame(ir, ALIGNMENT_FRAME_IDX, nz), MAX_DISPLACEMENT)\n",
    "h.prepareSumTensorsAndInvalidFrames((nz, nx, ny))\n",
    "t0 = timer()\n",
    "for chunkIdx in tqdm_notebook(range(chunkCount)):\n",
    "\n",
    "    # alternate chunks and queues to read current chunk and write last results into last chunk simultaneously\n",
    "    a, b = (0,1) if chunkIdx % 2 else (1,0)\n",
    "    thisChunk,      lastChunk      = (chunkPair[a],      chunkPair[b]) \n",
    "    thisFrameQueue, lastFrameQueue = (frameQueuePair[a], frameQueuePair[b])\n",
    "    \n",
    "    # read Frames and put them into current queue to be processed\n",
    "    chunkStart = chunkIdx*FRAMES_PER_CHUNK\n",
    "    for f in range(FRAMES_PER_CHUNK if chunkIdx < chunkCount-1 else nf % FRAMES_PER_CHUNK):\n",
    "        thisFrameQueue.put([h.readFrame(ir, chunkStart+f, nz), chunkStart+f, f, thisChunk])\n",
    "    \n",
    "    # save last chunk while processing this one (except at first chunk)\n",
    "    if chunkIdx > 0:\n",
    "        lastFrameQueue.join()\n",
    "        lastChunkStart = chunkStart - FRAMES_PER_CHUNK\n",
    "        dSetName = \"chunk\" + str(chunkIdx-1)\n",
    "        dd.io.save(\"test.h5\", {dSetName: lastChunk}, compression=('blosc',6))\n",
    "        #h5File[DATA_SET_NAME][:, lastChunkStart:chunkStart] = lastChunk.swapaxes(0,1)\n",
    "        \n",
    "    # at last chunk: save it because there is no next\n",
    "    if chunkIdx == chunkCount-1 or True: \n",
    "        thisFrameQueue.join()\n",
    "        chunkEnd = chunkStart + FRAMES_PER_CHUNK\n",
    "        dSetName = \"chunk\" + str(chunkIdx)\n",
    "        dd.io.save(\"test.h5\", {dSetName: thisChunk}, compression=('blosc',6))\n",
    "        #h5File[DATA_SET_NAME][:, chunkStart:chunkEnd] = thisChunk.swapaxes(0,1)\n",
    "np.save(\"regTime1.npy\", timer() - t0)\n",
    "print(timer() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_THREADS = 2\n",
    "# prepare reader\n",
    "ir, shape, metaData = h.startLifReader(FILE_NAME, FRAMES_PER_CHUNK)\n",
    "nf, nz, nx, ny = shape\n",
    "print(\"Found image stack of shape  {}\".format(shape))\n",
    "\n",
    "# prepare chunks\n",
    "chunkShape = (FRAMES_PER_CHUNK, nz, nx, ny)\n",
    "chunkCount = nf // FRAMES_PER_CHUNK\n",
    "chunkPair = (np.empty(chunkShape, dtype=np.uint16), np.empty(chunkShape, dtype=np.uint16))\n",
    "\n",
    "if (DELETE_LAST_H5_FILE): h.removeIfExists(H5_FILE_NAME)\n",
    "    \n",
    "# create Threads and Queues for image alignment\n",
    "frameQueuePair = (h.createQueue(h.alignFrameWorker, FRAMES_PER_CHUNK, MAX_THREADS, USE_GPU),\n",
    "                  h.createQueue(h.alignFrameWorker, FRAMES_PER_CHUNK, MAX_THREADS, USE_GPU))\n",
    "\n",
    "h.prepareAlignmentFrame(h.readFrame(ir, ALIGNMENT_FRAME_IDX, nz), MAX_DISPLACEMENT)\n",
    "h.prepareSumTensorsAndInvalidFrames((nz, nx, ny))\n",
    "t0 = timer()\n",
    "for chunkIdx in tqdm_notebook(range(chunkCount)):\n",
    "\n",
    "    # alternate chunks and queues to read current chunk and write last results into last chunk simultaneously\n",
    "    a, b = (0,1) if chunkIdx % 2 else (1,0)\n",
    "    thisChunk,      lastChunk      = (chunkPair[a],      chunkPair[b]) \n",
    "    thisFrameQueue, lastFrameQueue = (frameQueuePair[a], frameQueuePair[b])\n",
    "    \n",
    "    # read Frames and put them into current queue to be processed\n",
    "    chunkStart = chunkIdx*FRAMES_PER_CHUNK\n",
    "    for f in range(FRAMES_PER_CHUNK if chunkIdx < chunkCount-1 else nf % FRAMES_PER_CHUNK):\n",
    "        thisFrameQueue.put([h.readFrame(ir, chunkStart+f, nz), chunkStart+f, f, thisChunk])\n",
    "    \n",
    "    # save last chunk while processing this one (except at first chunk)\n",
    "    if chunkIdx > 0:\n",
    "        lastFrameQueue.join()\n",
    "    #    lastChunkStart = chunkStart - FRAMES_PER_CHUNK\n",
    "    #    h5File[DATA_SET_NAME][:, lastChunkStart:chunkStart] = lastChunk.swapaxes(0,1)\n",
    "        \n",
    "    # at last chunk: save it because there is no next\n",
    "    if chunkIdx == chunkCount-1 or True: \n",
    "        thisFrameQueue.join()\n",
    "    #    chunkEnd = chunkStart + FRAMES_PER_CHUNK\n",
    "    #    h5File[DATA_SET_NAME][:, chunkStart:chunkEnd] = thisChunk.swapaxes(0,1)\n",
    "np.save(\"regTime2.npy\", timer() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_THREADS = 4\n",
    "# prepare reader\n",
    "ir, shape, metaData = h.startLifReader(FILE_NAME, FRAMES_PER_CHUNK)\n",
    "nf, nz, nx, ny = shape\n",
    "print(\"Found image stack of shape  {}\".format(shape))\n",
    "\n",
    "# prepare chunks\n",
    "chunkShape = (FRAMES_PER_CHUNK, nz, nx, ny)\n",
    "chunkCount = nf // FRAMES_PER_CHUNK\n",
    "chunkPair = (np.empty(chunkShape, dtype=np.uint16), np.empty(chunkShape, dtype=np.uint16))\n",
    "\n",
    "if (DELETE_LAST_H5_FILE): h.removeIfExists(H5_FILE_NAME)\n",
    "    \n",
    "# create Threads and Queues for image alignment\n",
    "frameQueuePair = (h.createQueue(h.alignFrameWorker, FRAMES_PER_CHUNK, MAX_THREADS, USE_GPU),\n",
    "                  h.createQueue(h.alignFrameWorker, FRAMES_PER_CHUNK, MAX_THREADS, USE_GPU))\n",
    "\n",
    "h.prepareAlignmentFrame(h.readFrame(ir, ALIGNMENT_FRAME_IDX, nz), MAX_DISPLACEMENT)\n",
    "h.prepareSumTensorsAndInvalidFrames((nz, nx, ny))\n",
    "t0 = timer()\n",
    "for chunkIdx in tqdm_notebook(range(chunkCount)):\n",
    "\n",
    "    # alternate chunks and queues to read current chunk and write last results into last chunk simultaneously\n",
    "    a, b = (0,1) if chunkIdx % 2 else (1,0)\n",
    "    thisChunk,      lastChunk      = (chunkPair[a],      chunkPair[b]) \n",
    "    thisFrameQueue, lastFrameQueue = (frameQueuePair[a], frameQueuePair[b])\n",
    "    \n",
    "    # read Frames and put them into current queue to be processed\n",
    "    chunkStart = chunkIdx*FRAMES_PER_CHUNK\n",
    "    for f in range(FRAMES_PER_CHUNK if chunkIdx < chunkCount-1 else nf % FRAMES_PER_CHUNK):\n",
    "        thisFrameQueue.put([h.readFrame(ir, chunkStart+f, nz), chunkStart+f, f, thisChunk])\n",
    "    \n",
    "    # save last chunk while processing this one (except at first chunk)\n",
    "    if chunkIdx > 0:\n",
    "        lastFrameQueue.join()\n",
    "    #    lastChunkStart = chunkStart - FRAMES_PER_CHUNK\n",
    "    #    h5File[DATA_SET_NAME][:, lastChunkStart:chunkStart] = lastChunk.swapaxes(0,1)\n",
    "        \n",
    "    # at last chunk: save it because there is no next\n",
    "    if chunkIdx == chunkCount-1 or True: \n",
    "        thisFrameQueue.join()\n",
    "    #    chunkEnd = chunkStart + FRAMES_PER_CHUNK\n",
    "    #    h5File[DATA_SET_NAME][:, chunkStart:chunkEnd] = thisChunk.swapaxes(0,1)\n",
    "np.save(\"regTime4.npy\", timer() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_THREADS = 8\n",
    "# prepare reader\n",
    "ir, shape, metaData = h.startLifReader(FILE_NAME, FRAMES_PER_CHUNK)\n",
    "nf, nz, nx, ny = shape\n",
    "print(\"Found image stack of shape  {}\".format(shape))\n",
    "\n",
    "# prepare chunks\n",
    "chunkShape = (FRAMES_PER_CHUNK, nz, nx, ny)\n",
    "chunkCount = nf // FRAMES_PER_CHUNK\n",
    "chunkPair = (np.empty(chunkShape, dtype=np.uint16), np.empty(chunkShape, dtype=np.uint16))\n",
    "\n",
    "if (DELETE_LAST_H5_FILE): h.removeIfExists(H5_FILE_NAME)\n",
    "    \n",
    "# create Threads and Queues for image alignment\n",
    "frameQueuePair = (h.createQueue(h.alignFrameWorker, FRAMES_PER_CHUNK, MAX_THREADS, USE_GPU),\n",
    "                  h.createQueue(h.alignFrameWorker, FRAMES_PER_CHUNK, MAX_THREADS, USE_GPU))\n",
    "\n",
    "h.prepareAlignmentFrame(h.readFrame(ir, ALIGNMENT_FRAME_IDX, nz), MAX_DISPLACEMENT)\n",
    "h.prepareSumTensorsAndInvalidFrames((nz, nx, ny))\n",
    "t0 = timer()\n",
    "for chunkIdx in tqdm_notebook(range(chunkCount)):\n",
    "\n",
    "    # alternate chunks and queues to read current chunk and write last results into last chunk simultaneously\n",
    "    a, b = (0,1) if chunkIdx % 2 else (1,0)\n",
    "    thisChunk,      lastChunk      = (chunkPair[a],      chunkPair[b]) \n",
    "    thisFrameQueue, lastFrameQueue = (frameQueuePair[a], frameQueuePair[b])\n",
    "    \n",
    "    # read Frames and put them into current queue to be processed\n",
    "    chunkStart = chunkIdx*FRAMES_PER_CHUNK\n",
    "    for f in range(FRAMES_PER_CHUNK if chunkIdx < chunkCount-1 else nf % FRAMES_PER_CHUNK):\n",
    "        thisFrameQueue.put([h.readFrame(ir, chunkStart+f, nz), chunkStart+f, f, thisChunk])\n",
    "    \n",
    "    # save last chunk while processing this one (except at first chunk)\n",
    "    if chunkIdx > 0:\n",
    "        lastFrameQueue.join()\n",
    "    #    lastChunkStart = chunkStart - FRAMES_PER_CHUNK\n",
    "    #    h5File[DATA_SET_NAME][:, lastChunkStart:chunkStart] = lastChunk.swapaxes(0,1)\n",
    "        \n",
    "    # at last chunk: save it because there is no next\n",
    "    if chunkIdx == chunkCount-1 or True: \n",
    "        thisFrameQueue.join()\n",
    "    #    chunkEnd = chunkStart + FRAMES_PER_CHUNK\n",
    "    #    h5File[DATA_SET_NAME][:, chunkStart:chunkEnd] = thisChunk.swapaxes(0,1)\n",
    "np.save(\"regTime8.npy\", timer() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"regTime1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nf=20\n",
    "\n",
    "plainQueue = Queue(maxsize=2)\n",
    "for i in range(MAX_THREADS): h.createAndStartThreadWithQueue(h.alignPlainWorker, plainQueue)\n",
    "   \n",
    "h.prepareSumTensorsAndInvalidFrames((nz, nx, ny))\n",
    "for z in tqdm_notebook(range(nz)):\n",
    "    plainStack = h.readPlainStack(ir, z, nf)\n",
    "    \n",
    "    # push chunkwise to GPU because of limited Memory\n",
    "    for chunkf in range(0, nf, FRAMES_PER_CHUNK):\n",
    "        fRange = range(chunkf, chunkf+FRAMES_PER_CHUNK)\n",
    "        plainChunkTensor = h.toGPU(plainStack[fRange])\n",
    "        for f in range(FRAMES_PER_CHUNK):\n",
    "            plainQueue.put([plainChunkTensor, f, z, chunkf+f])\n",
    "        plainQueue.join()\n",
    "        plainStack[fRange] = h.toCPU(plainChunkTensor)\n",
    "        \n",
    "    name = \"plain{}\".format(z)\n",
    "    dd.io.save(H5_FILE_NAME, {\"stacks\":{name:plainStack}}, compression='blosc')\n",
    "    \n",
    "h.closeLifReader()\n",
    "\n",
    "# calc standard deviation and save invalid Frame indeces\n",
    "frameCount = nf - len(h.invalidFrames)\n",
    "stdDeviation = h.toCPU(th.sqrt((h.sumSqTensor - h.sumTensor**2/frameCount)/(frameCount-1)))\n",
    "imsave(STD_DEV_FILE_NAME, stdDeviation)\n",
    "np.save(INVALID_FRAMES_FILE_NAME, sorted(h.invalidFrames))\n",
    "\n",
    "#display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)  # kill kernel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
